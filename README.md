# DEMO

This is the description!

## Reproducibility Approach

Our project is committed to ensuring the reproducibility of our deduplication efforts. We have documented our methodology in detail, outlining the data processing steps, methods and models used, references to relevant scientific papers/sources, and the overall time required to identify duplicates within the dataset.

This comprehensive approach not only highlights the effectiveness of our methodology but also underscores our commitment to transparency and reproducibility in data science. Our process leverages advancements in Natural Language Processing (NLP) and employs transformer-based language models, such as BERT, alongside FAISS for efficient similarity searches among job advertisements. We further refine our methodology with expert rules to ensure accurate classification of duplicates.

For a full description of our reproducibility approach, including insights into the challenges faced and lessons learned throughout the project, refer to our documentation in the `assets` folder: [Reproducibility Approach Description](assets/reproducibility_approach_description.pdf)

